{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Template EDA : V2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "t9vffxyj0Rv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIVmDOT3Oj_T",
        "colab_type": "text"
      },
      "source": [
        "### 1. List all the datafiles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jmE6_4frOj_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "path = (\"../input\")\n",
        "fileList = os.listdir(path)\n",
        "df=[]\n",
        "for i,file in enumerate(fileList):\n",
        "    filename, file_extension = os.path.splitext(file)\n",
        "    file_df = pd.read_csv(path+'/'+file)\n",
        "    if filename==\"train\":\n",
        "        train = file_df\n",
        "    if filename==\"test\":\n",
        "        test = file_df\n",
        "    if filename==\"sample_submission\":\n",
        "        sample_submission = file_df\n",
        "    print (\"{} dataset has {} rows(samples) with {} columns(features) each.\".format(file,*file_df.shape))\n",
        "    print(file_df.head(2))\n",
        "    print()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1SL2OBZOj_W",
        "colab_type": "text"
      },
      "source": [
        "### 2. Instantiate the Exploratory Data Analysis Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fyRORnlBbin8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Instantiate the Exploratory Data Analysis Class\n",
        "#If you do not want to explore all variables, you can limit it to your choice. \n",
        "#If the last column in not your target column, specify target variable or label\n",
        "eda = explore(train,index_variable=None,label=None,include_variables=None,exclude_variables=None)\n",
        "\n",
        "#Show all the available functions in the eda class\n",
        "print([ m for m in dir(eda) if not m.startswith('__')])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODIp6t-MOj_Z",
        "colab_type": "text"
      },
      "source": [
        "### 3. Data Summary and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "D0-AmCcxOj_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check sample of the data\n",
        "eda.data_sample()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qHGtvXbZOj_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ucz6pIm0Oj_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.unique_value_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A174hjnxOj_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.missing_value_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aOOAiZs5Oj_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.duplicate_value_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAjdgIttOj_l",
        "colab_type": "text"
      },
      "source": [
        "### 4. Distribution of Numerical/Continous Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OBI0yFw70RwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.plot_hist() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lh2usCBWOj_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.box_plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "J4nUdd-8Oj_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.scatter_plot_independent_label()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HjISl1znOj_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.sns_heatmap()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-z90PaXKOj_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.pearson_correlation_matrix()      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0l34B5CWOj_x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " eda.outliers()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juyHu9TgOj_2",
        "colab_type": "text"
      },
      "source": [
        "### 5. Distribution of Categorical/Discreet Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "E7XcPnUPOj_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.percent_bar_chart()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ykcnjXYDOj_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.bar_chart() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kcZnpEC6Oj__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.cat_plot_independent_label()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fvE_qt9QOkAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.chi_square_test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FLtKpt2uOkAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(copy=True, iterated_power='auto', n_components=1, random_state=None,\n",
        "  svd_solver='auto', tol=0.0, whiten=False)\n",
        "pca.fit(train[num])\n",
        "\n",
        "# TODO: Transform the good data using the PCA fit above\n",
        "reduced_data = pca.transform(train[num])\n",
        "\n",
        "#display(reduced_data)\n",
        "# Create a DataFrame for the reduced data\n",
        "reduced_data = pd.DataFrame(reduced_data, columns = ['Dimension_1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QwakCtuvOkAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reduced_data['target']=train['target']\n",
        "reduced_data['log_data'] = np.log(reduced_data['Dimension_1'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Kp5dZpsvOkAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x='target'\n",
        "y='log_data'\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.scatterplot(x=x, y=y, palette=\"deep\", data=reduced_data);\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.xlabel(x)\n",
        "plt.ylabel(y)\n",
        "plt.title('Scatter plot of '+ x + ' and ' + y,size=16, y=1.05)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s05QXX-NXV5",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rzie_8mVNXqD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2MuIQiNNX8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 6. Timeseries Analysis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHJ88-Z2NYLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.time_series()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0BditL5NYW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.time_series_numerical_categorical() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1KcglEwN0Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.time_series_feature_label()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSNmvHcHN1Ni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eda.seasonality()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xFndoerOkAN",
        "colab_type": "text"
      },
      "source": [
        "### Explore Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "akDvCIDFOkAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Data Exploration/Clean Up/Transformation\n",
        "#data manipulation libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools as iter\n",
        "\n",
        "#Visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "from IPython.display import display,Markdown, HTML\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "from sklearn.decomposition import PCA\n",
        "import plotly.graph_objs as go\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "class explore(object):\n",
        "    def __init__(self, dataframe,index_variable=None,label=None,include_variables=None,exclude_variables=None):\n",
        "        self.dataframe=dataframe\n",
        "        if index_variable is None:\n",
        "            self.index_variable=dataframe.columns[0]\n",
        "        else:\n",
        "            self.index_variable=index_variable\n",
        "        if label is None:\n",
        "            self.label=dataframe.columns[len(dataframe.columns)-1]\n",
        "        else:\n",
        "            self.label=index_variable\n",
        "\n",
        "        print(label)\n",
        "        if (include_variables is not None):    \n",
        "            self.include_variables=include_variables\n",
        "        else:\n",
        "            self.include_variables=dataframe.columns\n",
        "        self.exclude_variables=exclude_variables\n",
        "        self.categorical_variables=self.get_categorical_variables()\n",
        "        self.numerical_variables=self.get_numerical_variables()\n",
        "    \n",
        "   \n",
        "    def get_categorical_variables(self): \n",
        "        cat_variables=list(self.dataframe.select_dtypes(include=[np.object,np.bool]).columns)\n",
        "        if self.index_variable in cat_variables:\n",
        "            cat_variables.remove(self.index_variable)\n",
        "        \n",
        "        if self.label is not None:\n",
        "            if self.label in cat_variables :\n",
        "                cat_variables.remove(self.label)\n",
        "\n",
        "        if self.exclude_variables is None:\n",
        "            cat_variables_filtered=cat_variables\n",
        "        else:\n",
        "            cat_variables_filtered=[elem for elem in cat_variables if elem not in self.exclude_variables] \n",
        "        return cat_variables_filtered;\n",
        "\n",
        "    def get_numerical_variables(self): \n",
        "        numerical_variables=list(self.dataframe.select_dtypes(include=[np.float,np.int]).columns)\n",
        "        if self.index_variable in numerical_variables:\n",
        "            numerical_variables.remove(self.index_variable)\n",
        "        \n",
        "        if self.label is not None:\n",
        "            if self.label in numerical_variables :\n",
        "                numerical_variables.remove(self.label)\n",
        "\n",
        "        if self.exclude_variables is None:\n",
        "            numerical_variables_filtered=numerical_variables\n",
        "        else:\n",
        "            numerical_variables_filtered=[elem for elem in cat_variables if elem not in self.exclude_variables] \n",
        "        return numerical_variables_filtered;\n",
        "\n",
        "    def data_sample(self):    \n",
        "        # a quick look at the sample of the data set\n",
        "        display (\" dataset has {} rows(samples) with {} columns(features) each.\".format(*self.dataframe.shape))\n",
        "        display(('--------------------Sample Dataset--------------------'))\n",
        "        display(self.dataframe.head().transpose())\n",
        "\n",
        "    def summary(self):\n",
        "\n",
        "        display(('--------------------5 Point Summary of Numeric Features--------------------'))\n",
        "        plt.show(self.dataframe.boxplot(figsize=(40,10), rot=45))\n",
        "\n",
        "        #dd=train.iloc[:,100:200].describe().transpose().reset_index()\n",
        "        dd=self.dataframe.describe().transpose().reset_index()\n",
        "        plt.figure(figsize=(40,20))\n",
        "        plt.errorbar(range(len(dd['index'])), dd['mean'],markersize=10, capsize=4,yerr=dd['std'], fmt='o')\n",
        "        plt.xticks(range(len(dd['index'])), dd['index'],rotation=45)\n",
        "        plt.show()\n",
        "\n",
        "        display(dd) \n",
        "     \n",
        "    def unique_value_count(self):   \n",
        "        #Information on the data type\n",
        "        display(('--------------------Plot Unique Value Counts and DataType for each Feature--------------------'))\n",
        "        col_info=pd.DataFrame(columns=['col_name','label','unique_values'])\n",
        "        for col in self.dataframe.columns:\n",
        "            row = [col, self.dataframe[col].dtype , self.dataframe[col].nunique()]\n",
        "            col_info.loc[len(col_info)] = row\n",
        "\n",
        "        col_info['label']=col_info['label'].astype('str')\n",
        "        plt.figure(figsize=(40,20))\n",
        "        sns.catplot(x='col_name', y='unique_values', hue='label', kind='bar', data=col_info, height=6, aspect=col_info.shape[0]/10+2)\n",
        "            \n",
        "        plt.xticks(rotation=90)\n",
        "        plt.show()\n",
        "\n",
        "        display(('--------------------Unique Values for each categorical feature--------------------'))\n",
        "        for col in list(self.dataframe.select_dtypes(include=[np.object,np.bool]).columns):\n",
        "            print('Column Name: {} : {}'.format(col,self.dataframe[col].unique()))\n",
        "        #display(('--------------------Unique Value Counts and DataType for each Feature--------------------'))\n",
        "        #for col in list(self.dataframe.columns):\n",
        "        #    print('Column Name: {} DataType: {} : {}'.format(col,self.dataframe[col].dtype,self.dataframe[col].nunique()))\n",
        "    \n",
        "    def missing_value_count(self): \n",
        "        display(('--------------------% of 0 Values per column--------------------'))\n",
        "        num_col_0_values=self.dataframe.columns[self.dataframe.eq(0).any()].size\n",
        "        print('Number of columns with 0 values : {}'.format(num_col_0_values))\n",
        "        col_info=pd.DataFrame(columns=['col_name','zero_value_pct'])\n",
        "        for col in self.dataframe.columns:\n",
        "              row = [col, (self.dataframe[col].eq(0).sum()*100.0)/self.dataframe.shape[0]]\n",
        "              col_info.loc[len(col_info)] = row\n",
        "\n",
        "        #col_info['label']=col_info['label'].astype('str')\n",
        "        plt.figure(figsize=(40,20))\n",
        "        sns.catplot(x='col_name', y='zero_value_pct', kind='bar', data=col_info, height=6, aspect=round(num_col_0_values/10)+2)\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.show()\n",
        "\n",
        "        #for col in self.dataframe.columns[self.dataframe.eq(0).any()].tolist():\n",
        "        #    print('{} : {} % '.format(col,(self.dataframe[col].eq(0).sum()*100.0)/self.dataframe.shape[0]))\n",
        "\n",
        "        display(('--------------------% of Null Values per column--------------------'))\n",
        "        num_col_null_values=self.dataframe.columns[self.dataframe.isnull().any()].size\n",
        "        \n",
        "        print('Number of columns with null values : {}'.format(num_col_null_values))\n",
        "        col_info=pd.DataFrame(columns=['col_name','null_value_pct'])\n",
        "        for col in self.dataframe.columns:\n",
        "              row = [col, (self.dataframe[col].isnull().sum()*100.0)/self.dataframe.shape[0]]\n",
        "              col_info.loc[len(col_info)] = row\n",
        "\n",
        "        #col_info['label']=col_info['label'].astype('str')\n",
        "        plt.figure(figsize=(40,20))\n",
        "        sns.catplot(x='col_name', y='null_value_pct', kind='bar', data=col_info, height=6, aspect=round(num_col_null_values/10)+2)\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.show()\n",
        "        #for col in self.dataframe.columns[self.dataframe.isnull().any()].tolist():\n",
        "        #    print('{} : {} % '.format(col,(self.dataframe[col].isnull().sum()*100.0)/self.dataframe.shape[0]))\n",
        "\n",
        "        display(('--------------------% of NaN/Inf Values per column--------------------'))\n",
        "        num_sql_nan_inf_values=self.dataframe.isin([np.nan, np.inf, -np.inf]).any().size\n",
        "        print('Number of columns with Nan/Inf Values :{}'.format(num_sql_nan_inf_values))\n",
        "        \n",
        "        col_info=pd.DataFrame(columns=['col_name','nan_inf_value_pct'])\n",
        "        for col in self.dataframe.columns:\n",
        "              row = [col, (self.dataframe[col].isin([np.nan, np.inf, -np.inf]).sum()*100.0)/self.dataframe.shape[0]]\n",
        "              col_info.loc[len(col_info)] = row\n",
        "\n",
        "        plt.figure(figsize=(40,20))\n",
        "        sns.catplot(x='col_name', y='nan_inf_value_pct', kind='bar', data=col_info, height=6, aspect=round(num_sql_nan_inf_values/10)+2)\n",
        "        plt.xticks(rotation=90)\n",
        "        plt.show()\n",
        "\n",
        "        #for col in self.dataframe.columns[self.dataframe.isin([np.nan, np.inf, -np.inf]).any()].tolist():\n",
        "        #    print('{} : {} % '.format(col,(self.dataframe[col].isin([np.nan, np.inf, -np.inf]).sum()*100.0)/self.dataframe.shape[0]))\n",
        "            \n",
        "    def duplicate_value_count(self):              \n",
        "        display(('--------------------Duplicate Rows--------------------'))\n",
        "        display(self.dataframe.duplicated().any())\n",
        "      \n",
        "    \n",
        "    def show_numerical_variable_plots(self):\n",
        "        self.plot_hist()\n",
        "        self.box_plot()\n",
        "        self.scatter_plot_independent_label()\n",
        "        sns.set()\n",
        "        plt.figure(figsize=(10,10)) \n",
        "        sns.heatmap(self.dataframe.corr(),annot=True,cmap=\"Blues\",fmt=\".2f\",linewidths=.05)\n",
        "        self.pearson_correlation_matrix()\n",
        "        self.check_for_outliers();\n",
        "        \n",
        "    def show_categorical_variable_plots(self):\n",
        "        self.percent_bar_chart()\n",
        "        self.chi_square_test()\n",
        "        self.bar_chart()\n",
        "        self.cat_plot_independent_label() \n",
        "        \n",
        "    \n",
        "        \n",
        "    def plot_hist(self):\n",
        "        display(Markdown('**--------------------Histograms of each Feature--------------------**'))\n",
        "       \n",
        "        for col in self.numerical_variables:\n",
        "            plt.figure(figsize=(10,5))\n",
        "            #plt.hist(dataframe[col], bins=10)\n",
        "           # print(col)\n",
        "            s=self.dataframe[col].dropna()\n",
        "            #w = 100*(np.zeros_like(s) + 1. / len(s))\n",
        "            plt.hist(s)\n",
        "            plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
        "            plt.xlabel(col)\n",
        "            plt.ylabel('Frequency')\n",
        "            plt.title('Histogram of '+ col)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "    \n",
        "    def sns_heatmap(self):\n",
        "        sns.set()\n",
        "        plt.figure(figsize=(10,10)) \n",
        "        sns.heatmap(self.dataframe.corr(),annot=True,cmap=\"Blues\",fmt=\".2f\",linewidths=.05)\n",
        "        plt.show()\n",
        "        \n",
        "    def bar_chart(self):\n",
        "        display(('--------------------bar chart of categorial variables--------------------'))\n",
        "   \n",
        "        for x in self.categorical_variables:\n",
        "           # if x != y:\n",
        "            sns.catplot(x=x, kind=\"count\", palette=\"deep\", data=self.dataframe,height=5, aspect=2);\n",
        "            plt.xlabel(x)\n",
        "            plt.xticks(rotation='vertical')\n",
        "            plt.ylabel('Frequency')\n",
        "            plt.title('Bar chart of '+ x ,size=16, y=1.05)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "            display('==============================================================================================================')\n",
        "\n",
        "    def plot_density(self):\n",
        "        display(Markdown('**--------------------Density Plot of each Feature--------------------**'))\n",
        "   \n",
        "        for col in self.numerical_variables:\n",
        "            plt.figure(figsize=(10,5))\n",
        "            plt.hist(self.dataframe[col], bins=10)\n",
        "            plt.xlabel(col)\n",
        "            plt.ylabel('Frequency')\n",
        "            sns.distplot(self.dataframe[col], hist=True, kde=True, \n",
        "                 bins=int(180/5), color = 'darkblue', \n",
        "                 hist_kws={'edgecolor':'black'},\n",
        "                 kde_kws={'linewidth': 4})\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "            \n",
        "    def pair_plot(self):\n",
        "        display(Markdown('**--------------------Pairplot of all Features with continous numeric value--------------------**'))\n",
        "        for x,y in iter.combinations(self.include_variables,2):\n",
        "            #if x != y:\n",
        "                plt.figure(figsize=(10,5))\n",
        "                plt.scatter(self.dataframe[x],self.dataframe[y])\n",
        "                plt.xlabel(x)\n",
        "                plt.ylabel(y)\n",
        "                plt.title('Pairplot of '+ x + ' and ' + y)\n",
        "                plt.grid(True)\n",
        "                plt.show()\n",
        "\n",
        "    def bar_chart_xyz(self):\n",
        "        display(Markdown('**--------------------bar plot of each column segmented by another column--------------------**'))\n",
        "\n",
        "        for x,y,z in iter.combinations(self.include_variables,3):\n",
        "           # if x != y:\n",
        "            sns.catplot(x=x, hue=y,col=z, kind=\"count\", palette=\"deep\", data=self.dataframe,height=20, aspect=2);\n",
        "            plt.xlabel(x)\n",
        "            plt.ylabel(y)\n",
        "            plt.title('Bar plot of '+ x + ' and ' + y)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "    def retention_funnel(self,funnel_level,aggregate_column):\n",
        "        display(Markdown('**--------------------retention funnel of each column by billing cycles--------------------**'))\n",
        "\n",
        "        for x in self.include_variables:\n",
        "            if x !=funnel_level and x!=aggregate_column:\n",
        "                df_group=self.dataframe.groupby([funnel_level,x])[aggregate_column].agg('count').unstack()\n",
        "                pct=round((df_group.pct_change()+1)*100,0)\n",
        "                #display(pct)\n",
        "                pct.plot(figsize=(10,5))\n",
        "                plt.xlabel(x)     \n",
        "\n",
        "    def bar_chart_2_variables(self):\n",
        "        display(('--------------------bar plot of each categorical variables segmented by another categorical variables--------------------'))\n",
        "\n",
        "        for x,y in iter.combinations(self.include_variables,2):\n",
        "           # if x != y:\n",
        "            sns.catplot(x=x, hue=y, kind=\"count\", palette=\"deep\", data=self.dataframe,height=5, aspect=2);\n",
        "            plt.xticks(rotation='vertical')\n",
        "            plt.xlabel(x)\n",
        "            plt.ylabel(y)\n",
        "            plt.title('Bar plot of '+ x + ' and ' + y,size=16, y=1.05)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "    def bar_chart_independent_label(self):\n",
        "        display(('--------------------bar plot of each categorical variables segmented by another categorical variables--------------------'))\n",
        "        y=label;\n",
        "        for x in self.include_variables:\n",
        "           # if x != y:\n",
        "            sns.catplot(x=x, hue=y, kind=\"count\", palette=\"deep\", data=self.dataframe,height=5, aspect=2);\n",
        "            plt.xticks(rotation='vertical')\n",
        "            plt.xlabel(x)\n",
        "            plt.ylabel(y)\n",
        "            plt.title('Bar plot of '+ x + ' and ' + y,size=16, y=1.05)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "    def bar_chart(self):\n",
        "        display(Markdown('**--------------------bar plot of each column segmented by another column--------------------**'))\n",
        "\n",
        "        for x,y in iter.combinations(self.include_variables,2):\n",
        "           # if x != y:\n",
        "            sns.catplot(x=x, hue=y, kind=\"count\", palette=\"deep\", data=self.dataframe,height=5, aspect=2);\n",
        "            plt.xlabel(x)\n",
        "            plt.ylabel(y)\n",
        "            plt.title('Bar plot of '+ x + ' and ' + y)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "    def percent_bar_chart(self):\n",
        "        display(Markdown('**--------------------bar plot of each column segmented by another column--------------------**'))\n",
        "\n",
        "        for x,y in iter.combinations(self.include_variables,2):\n",
        "           # if x != y:\n",
        "            freq_df = self.dataframe.groupby([x])[y].value_counts(normalize=True).unstack()\n",
        "            pct_df = freq_df.divide(freq_df.sum(axis=1), axis=0)\n",
        "            pct_df.plot(kind=\"bar\",figsize=(10,5))\n",
        "            plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
        "            plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2,1.0))\n",
        "            plt.xlabel(x)\n",
        "            plt.ylabel(y)\n",
        "            plt.title('Bar plot of '+ x + ' and ' + y)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "    def cat_plot_independent_label(self):\n",
        "        display(('--------------------bar plot of each categorical variables segmented by another categorical variables--------------------'))\n",
        "        y=label;\n",
        "        for x in self.include_variables:\n",
        "           # if x != y:\n",
        "            #sns.catplot(x=x, hue=y, kind=\"count\", palette=\"deep\", data=self.dataframe,height=5, aspect=2);\n",
        "            sns.catplot(x=x, y=y, data=df,height=5, aspect=2);\n",
        "            plt.xticks(rotation='vertical')\n",
        "            plt.xlabel(x)\n",
        "            plt.ylabel(y)\n",
        "            plt.title('Bar plot of '+ x + ' and ' + y,size=16, y=1.05)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "    def scatter_plot_independent_label(self):\n",
        "        display(('--------------------scatter plot numerical variables by label--------------------'))\n",
        "        x=self.label;\n",
        "        for y in self.numerical_variables:\n",
        "           # if x != y:\n",
        "            plt.figure(figsize=(10,5))\n",
        "            sns.scatterplot(x=x, y=y, palette=\"deep\", data=self.dataframe);\n",
        "            plt.xticks(rotation='vertical')\n",
        "            plt.xlabel(x)\n",
        "            plt.ylabel(y)\n",
        "            plt.title('Scatter plot of '+ x + ' and ' + y,size=16, y=1.05)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "\n",
        "    def percent_bar_chart(self):\n",
        "        display(('--------------------bar plot of each column segmented by another column--------------------'))\n",
        "\n",
        "        for x,y in iter.combinations(self.include_variables,2):\n",
        "           # if x != y:\n",
        "            freq_df = self.dataframe.groupby([x])[y].value_counts(normalize=True).unstack()\n",
        "            pct_df = freq_df.divide(freq_df.sum(axis=1), axis=0)\n",
        "            pct_df.plot(kind=\"bar\",figsize=(10,5))\n",
        "            plt.gca().yaxis.set_major_formatter(IndexFormatter(1))\n",
        "            plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2,1.0))\n",
        "            plt.xlabel(x)\n",
        "            plt.ylabel(y)\n",
        "            plt.title('Bar plot of '+ x + ' and ' + y,size=16, y=1.05)\n",
        "            plt.grid(True)\n",
        "            plt.show()       \n",
        "\n",
        "    def percentage_barh_stacked_chart(self):\n",
        "        display(Markdown('**--------------------percentage chart for categorical variables--------------------**'))\n",
        "\n",
        "        for x,y in iter.combinations(self.include_variables,2):\n",
        "            #if x != y:\n",
        "                cont_table=pd.crosstab(self.dataframe[x],self.dataframe[y], normalize='index')\n",
        "                #print(cont_table)\n",
        "                cont_table.plot(kind='barh', stacked=True,figsize=(10,5))\n",
        "                plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2,1.0))\n",
        "                plt.xlabel(x)\n",
        "                plt.ylabel(y)\n",
        "                plt.title('Bar plot of '+ x + ' and ' + y)\n",
        "                plt.grid(True)\n",
        "                plt.show()\n",
        "\n",
        "    def line_plot_multiple(self):\n",
        "        display(('--------------------time series plot of each variable --------------------'))\n",
        "\n",
        "        for x in self.categorical_variables:\n",
        "                plt.figure(figsize=(15,10))\n",
        "                df_d=self.dataframe.groupby([timeseries,x], as_index=False)[value].agg({'group_size':'sum'})\n",
        "                sns.lineplot(data=df_d, x=timeseries, hue=x,  y=\"group_size\")\n",
        "                plt.title('Time series plot of '+ x + ' and ' + timeseries,size=16, y=1.05)\n",
        "                plt.ylabel(x)\n",
        "                plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2,1.0))\n",
        "                plt.xlabel(timeseries)\n",
        "                plt.grid(True)\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "    def line_plot(self):\n",
        "        display(Markdown('**--------------------box plot of each column segmented by another column--------------------**'))\n",
        "\n",
        "        for x in self.categorical_variables:\n",
        "                plt.figure(figsize=(15,10))\n",
        "                df_d=self.dataframe.groupby([timeseries,x], as_index=False)[value].agg({'group_size':'sum'})\n",
        "                sns.lineplot(data=df_d, x=timeseries, hue=x,  y=\"group_size\") \n",
        "                plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2,1.0))\n",
        "                plt.ylabel(x)\n",
        "                plt.xlabel(timeseries)\n",
        "                plt.title('Time series plot of '+ x + ' and ' + timeseries)\n",
        "                plt.grid(True)\n",
        "                plt.show()\n",
        "\n",
        "    def box_plot(self):\n",
        "        display(Markdown('**--------------------box plot of each column segmented by another column--------------------**'))\n",
        "\n",
        "        for x, y in ([(m , n) for m in self.categorical_variables for n in self.numerical_variables ]):\n",
        "                plt.figure(figsize=(15,10))\n",
        "                sns.boxplot(x=x, y=y, linewidth=2.5,data=self.dataframe)\n",
        "                plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2,1.0))\n",
        "                plt.xlabel(x)\n",
        "                plt.ylabel(y)\n",
        "                plt.title('Box plot of '+ x + ' and ' + y)\n",
        "                plt.grid(True)\n",
        "                plt.show()\n",
        "\n",
        "    def box_plot_categorical_label(self):\n",
        "        display(('--------------------box plot of dependent varaible for categorical variable--------------------'))\n",
        "\n",
        "        for y in self.categorical_variables:\n",
        "                #sns.catplot(y=label, x=y, linewidth=2.5, kind=\"box\",data=self.dataframe,height=5, aspect=2)\n",
        "                plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2,1.0))\n",
        "                plt.xticks(rotation='vertical')\n",
        "                plt.xlabel(label)\n",
        "                plt.ylabel(y)\n",
        "                sns.set_style(\"whitegrid\")\n",
        "                ax = sns.boxplot(x=y, y=label, data=self.dataframe)\n",
        "\n",
        "                plt.title('Box plot of '+ y,size=16, y=1.05 )\n",
        "                medians = self.dataframe.groupby([y])[label].median().values\n",
        "                median_labels = [str(np.round(s, 2)) for s in medians]\n",
        "\n",
        "                pos = range(len(medians))\n",
        "                for tick,label in zip(pos,ax.get_xticklabels()):\n",
        "                    ax.text(pos[tick], medians[tick] + 0.5, median_labels[tick], \n",
        "                    horizontalalignment='center', size='x-small', color='w', weight='semibold')\n",
        "                plt.grid(True)\n",
        "                plt.show()\n",
        "    def time_series_feature_label(self):\n",
        "        for n in self.numerical_variables:\n",
        "          plt.xlabel('Time series of target and independent variables')\n",
        "          df=self.dataframe\n",
        "          df[self.date_variable]=pd.to_datetime(df[self.date_variable])\n",
        "          df.index=df[self.date_variable]\n",
        "          feature_plot=df[n]\n",
        "          target_plot=df[self.label]\n",
        "          ax1 = feature_plot.plot(color='blue',x=self.date_variable, grid=True, label=n)\n",
        "          ax2 = target_plot.plot(color='red', x=self.date_variable, grid=True, secondary_y=True, label=self.label)\n",
        "          h1, l1 = ax1.get_legend_handles_labels()\n",
        "          h2, l2 = ax2.get_legend_handles_labels()\n",
        "          plt.legend(h1+h2, l1+l2, loc=2)\n",
        "          plt.show()\n",
        "    \n",
        "    def seasonality(self):\n",
        "      display(('--------------------Seasonality plot of each variable --------------------'))\n",
        "      for n  in self.numerical_variables:\n",
        "              season = self.dataframe.copy()\n",
        "              season['Year'] = season['Date'].dt.year\n",
        "              season['Day'] = season['Date'].dt.dayofyear\n",
        "              spivot = pd.pivot_table(season, index='Day', columns = 'Year', values = n)\n",
        "              spivot.plot(linewidth=3)\n",
        "              plt.title('Seasonality plot of '+ n + ' and ' + self.date_variable,size=16, y=1.05)\n",
        "              plt.show()\n",
        "              \n",
        "    def time_series_numerical_categorical(self):\n",
        "        display(('--------------------bar plot of each numerical variables segmented by a categorical variables--------------------'))\n",
        "        for a,b in [(m,n) for m in self.categorical_variables   for n in self.numerical_variables]:\n",
        "           # if x != y:\n",
        "            \n",
        "            sns.lineplot(data=self.dataframe, x=self.date_variable, hue=a,  y=b)\n",
        "           \n",
        "            plt.title('Time series plot of '+ b + ' and ' + self.date_variable,size=16, y=1.05)\n",
        "            plt.ylabel(b)\n",
        "            plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2,1.0))\n",
        "            plt.xlabel(self.date_variable)\n",
        "            plt.xticks(rotation=90)\n",
        "            plt.grid(True)\n",
        "            plt.show()\n",
        "            \n",
        "            \n",
        "    \n",
        "\n",
        "    def time_series(self):\n",
        "        display(('--------------------time series plot of each variable --------------------'))\n",
        "\n",
        "        for n in self.numerical_variables:\n",
        "                #plt.figure(figsize=(15,10))\n",
        "                self.dataframe.plot(x=self.date_variable, y=n)\n",
        "                plt.title('Time series plot of '+ n + ' and ' + self.date_variable,size=16, y=1.05)\n",
        "                plt.ylabel(n)\n",
        "                plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2,1.0))\n",
        "                plt.xlabel(self.date_variable)\n",
        "                plt.xticks(rotation=90)\n",
        "                plt.grid(True)\n",
        "                plt.show()\n",
        "    # Pearson Correlation gives the correlation and p-value\n",
        "\n",
        "    def pearson_correlation_matrix(self):\n",
        "        display(('--------------------pearson correlation--------------------'))\n",
        "        corr_df = pd.DataFrame(columns=['feature', 'correlation', 'p_value'])\n",
        "        rows_list = []\n",
        "        y=self.label\n",
        "        for x in self.numerical_variables:\n",
        "         # if x != y:\n",
        "          display('Pearson Correlation between ' + x + ' and ' + y);\n",
        "          display(pearsonr(df[x],df[y]));\n",
        "          display('-----------------------------------------------');\n",
        "          correlation,p_value=pearsonr(df[x],df[y])\n",
        "          dict1 = {}\n",
        "          dict1 = {'column':x,'correlation':correlation,'p_value':p_value}\n",
        "          rows_list.append(dict1)\n",
        "\n",
        "        corr_df = pd.DataFrame(rows_list);  \n",
        "        display(corr_df);\n",
        "\n",
        "    # Correlation Matrix Heatmap\n",
        "    def correlation_matrix_continuous(self):\n",
        "        display(Markdown('**--------------------Correlation matrix continous numeric features--------------------**'))\n",
        "\n",
        "        f, ax = plt.subplots(figsize=(10, 6))\n",
        "        hm = sns.heatmap(round(df.corr(),2), annot=True, ax=ax, cmap=\"coolwarm\",fmt='.2f',\n",
        "                     linewidths=.05)\n",
        "        f.subplots_adjust(top=0.93)\n",
        "        t= f.suptitle('Correlation Heatmap', fontsize=14)   \n",
        "\n",
        "\n",
        "    def chi_square_test(self):\n",
        "        display(Markdown('**--------------------percentage chart for categorical variables--------------------**'))\n",
        "        #final_columns=[col for col in include_columns if col not in exclude_columns]\n",
        "\n",
        "        for x,y in iter.combinations(self.include_variables,2):\n",
        "            #if x != y:\n",
        "                crosstable=pd.crosstab(self.dataframe[x],self.dataframe[y], normalize='index')\n",
        "                cont_table=pd.crosstab(self.dataframe[x],self.dataframe[y])\n",
        "                #print(cont_table)\n",
        "                crosstable.plot(kind='barh', stacked=True,figsize=(10,5))\n",
        "                plt.legend(loc=\"upper right\", bbox_to_anchor=(1.2,1.0))\n",
        "                #plt.xlabel(x)\n",
        "                plt.ylabel(x)\n",
        "                plt.title('Bar plot of '+ x + ' and ' + y)\n",
        "                plt.grid(True)\n",
        "                plt.show()\n",
        "                chi2,p,df=chi2_contingency(cont_table)[0:3]\n",
        "                print('**The Null and Alternate Hypotheses**')\n",
        "\n",
        "                print('H0:There is no statistically significant relationship between the two selected variables')\n",
        "                print('Ha:There is a statistically significant relationship between the two selected variables')\n",
        "\n",
        "\n",
        "\n",
        "                if p < .05:\n",
        "                    print(\"We can reject the Null Hypothesis and say that \" + x + \" and \" + y + \" have some relationship\")\n",
        "                else:\n",
        "                    print(\"We cannot reject the Null hypothesis and say that \" + x + \" and \" + y + \" are truly independent\")\n",
        "                print()\n",
        "                print (\"X2: {}, p-value: {}, Degrees of Freedom: {}\".format(chi2,p,df))\n",
        "\n",
        "    def outliers(self,drop_outlier=False):\n",
        "    \n",
        "        # For each feature find the data points with extreme high or low values\n",
        "        log_data=self.dataframe\n",
        "        x=[]\n",
        "        for feature in log_data.keys():\n",
        "    \n",
        "            # TODO: Calculate Q1 (25th percentile of the data) for the given feature\n",
        "            Q1 = np.percentile(log_data[feature],25)\n",
        "\n",
        "            # TODO: Calculate Q3 (75th percentile of the data) for the given feature\n",
        "            Q3 = np.percentile(log_data[feature],75)\n",
        "\n",
        "            # TODO: Use the interquartile range to calculate an outlier step (1.5 times the interquartile range)\n",
        "            step = 1.5*(Q3-Q1)\n",
        "            y= log_data[~((log_data[feature] >= Q1 - step) & (log_data[feature] <= Q3 + step))]\n",
        "            y1=y.index.values\n",
        "            x.append(y1)\n",
        "            # Display the outliers\n",
        "            #outliercount=y.shape[0]\n",
        "            #print (\"'{} Data points considered outliers for the feature '{}':\".format(outliercount,feature))\n",
        "\n",
        "\n",
        "            # OPTIONAL: Select the indices for data points you wish to remove\n",
        "            # Here I go through the lists and extract the index value that is repeated in more than one list.\n",
        "            seen = set()\n",
        "            repeated = set()\n",
        "        for l in x:\n",
        "            for i in set(l):\n",
        "                if i in seen:\n",
        "                  repeated.add(i)\n",
        "                else:\n",
        "                  seen.add(i)\n",
        "\n",
        "        outliers =list(repeated)\n",
        "        outlier_count=len(outliers)\n",
        "        total_count=len(log_data)\n",
        "       \n",
        "        percent_outliers=(float(outlier_count)*100)/(float(total_count))\n",
        "        #display(percent_outliers)\n",
        "        delete_status = \"Outlier not dropped from dataset\"\n",
        "\n",
        "        if drop_outlier is True:\n",
        "            # Remove the outliers, if any were specified\n",
        "            good_data = data.loc[~data.index.isin(outliers)]\n",
        "            delete_status = \"Outlier Dropped from dataset\"\n",
        "            data=good_data\n",
        "\n",
        "        message =(\"{} ({:2.2f}%) data points considered outliers from the dataset of {}. {}.\".format(outlier_count,percent_outliers,total_count,delete_status))   \n",
        "        return data,outliers , message\n",
        "\n",
        "    def pca_results(self,n_components=6):\n",
        "\n",
        "        pca = PCA(copy=True, iterated_power='auto', n_components=n_components, random_state=42,\n",
        "        svd_solver='auto', tol=0.0, whiten=False)\n",
        "        df_pca=self.dataframe[self.numerical_variables]\n",
        "        pca.fit(df_pca)\n",
        "      \n",
        "\n",
        "        dimensions = dimensions = ['Dimension {}'.format(i) for i in range(1,len(pca.components_)+1)]\n",
        "\n",
        "        # PCA components\n",
        "        components = pd.DataFrame(np.round(pca.components_, 4), columns = list(df_pca.keys()))\n",
        "        components.index = dimensions\n",
        "\n",
        "        # PCA explained variance\n",
        "        ratios = pca.explained_variance_ratio_.reshape(len(pca.components_), 1)\n",
        "        variance_ratios = pd.DataFrame(np.round(ratios, 4), columns = ['Explained Variance'])\n",
        "        variance_ratios.index = dimensions\n",
        "\n",
        "        # Create a bar plot visualization\n",
        "        fig, ax = plt.subplots(figsize = (14,8))\n",
        "\n",
        "        # Plot the feature weights as a function of the components\n",
        "        components.plot(ax = ax, kind = 'bar');\n",
        "        ax.set_ylabel(\"Feature Weights\")\n",
        "        ax.set_xticklabels(dimensions, rotation=0)\n",
        "\n",
        "\n",
        "          # Display the explained variance ratios\n",
        "        for i, ev in enumerate(pca.explained_variance_ratio_):\n",
        "            ax.text(i-0.40, ax.get_ylim()[1] + 0.05, \"Explained Variance\\n          %.4f\"%(ev))\n",
        "\n",
        "        # Return a concatenated DataFrame\n",
        "        pca_results=pd.concat([variance_ratios, components], axis = 1)\n",
        "        #pca_results_cumsum=pca_results['Explained Variance'].cumsum()\n",
        "        return pca"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CN-unwiOkAP",
        "colab_type": "text"
      },
      "source": [
        "### Transform: Remove/Impute/Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SFdGVPaTOkAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class pre(object):\n",
        "    def __init__(self, dataframe,index_variable=None,label=None,include_variables=None,exclude_variables=None,eda=eda):\n",
        "        self.dataframe=dataframe\n",
        "        if index_variable is None:\n",
        "            self.index_variable=dataframe.columns[0]\n",
        "        else:\n",
        "            self.index_variable=index_variable\n",
        "        if label is None:\n",
        "            self.label=dataframe.columns[len(dataframe.columns)-1]\n",
        "        else:\n",
        "            self.label=index_variable\n",
        "        if (include_variables is not None):    \n",
        "            self.include_variables=include_variables\n",
        "        else:\n",
        "            self.include_variables=dataframe.columns\n",
        "        self.exclude_variables=exclude_variables\n",
        "        self.categorical_variables=eda.get_categorical_variables()\n",
        "        self.numerical_variables=eda.get_numerical_variables()\n",
        "    \n",
        "    def normalize_data(self):\n",
        "        #normalize all the columns(features) so that all the values in the column lie between 0 and 1\n",
        "        #this way each features will get equal preference regardless of their actual range\n",
        "        n_data=pd.DataFrame(data=self.dataframe)\n",
        "        n_data[numerical_variables] = preprocessing.normalize(data),columns=numerical_variables\n",
        "        return n_data\n",
        "\n",
        "    \n",
        "    def drop_outliers(self):\n",
        "        eda.outliers(drop_outlier=True)\n",
        "  \n",
        "      #sample function call\n",
        "      #resample(X_train,y_train,'target',['up_sample','down_sample']):\n",
        "    def resample(features,target,sample_type):\n",
        "        X_y_train = pd.concat([features,target],axis=1)\n",
        "        X_y_train_1s = X_y_train[X_y_train[target_label] == 1]\n",
        "        X_y_train_0s = X_y_train[X_y_train[target_label] == 0]\n",
        "        if (sample_type==\"up_sample\"):\n",
        "            rep_1 =[X_y_train_1s for x in range(X_y_train_0s.shape[0]//X_y_train_1s.shape[0] )]\n",
        "            keep_1s = pd.concat(rep_1, axis=0)\n",
        "            X_y_train = pd.concat([X_y_train_0s,keep_1s],axis=0)\n",
        "        else:\n",
        "            keep_0s = X_y_train_0s.sample(frac=X_y_train_1s.shape[0]/X_y_train_0s.shape[0]) \n",
        "            X_y_train = pd.concat([X_y_train_0s,keep_1s],axis=0)\n",
        "\n",
        "        y_train=X_y_train[label]\n",
        "        X_train=X_y_train[numerical_variables]\n",
        "        return (X_train,y_train)\n",
        "\n",
        "    def encode_categorical_variables(df):\n",
        "        return df.dummy()\n",
        "    \n",
        "    def log_scale():"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "V_kj1TCEOkAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt=transform(train,index_variable=None,label=None,include_variables=None,exclude_variables=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fegZo9tTOkAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt.normalize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sTukOShqOkAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt.drop_outliers()\n",
        "       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JRd_UncAOkAe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt.resample()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dHMhHg7cOkAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dt.log_scale()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9RZ2_ATVOkAh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Feature_Engineering(object):\n",
        "    def __init__(self, dataframe,index_variable=None,label=None,include_variables=None,exclude_variables=None,eda=eda):\n",
        "        self.dataframe=dataframe\n",
        "        if index_variable is None:\n",
        "            self.index_variable=dataframe.columns[0]\n",
        "        else:\n",
        "            self.index_variable=index_variable\n",
        "        if label is None:\n",
        "            self.label=dataframe.columns[len(dataframe.columns)-1]\n",
        "        else:\n",
        "            self.label=index_variable\n",
        "        if (include_variables is not None):    \n",
        "            self.include_variables=include_variables\n",
        "        else:\n",
        "            self.include_variables=dataframe.columns\n",
        "        self.exclude_variables=exclude_variables\n",
        "        self.categorical_variables=eda.get_categorical_variables()\n",
        "        self.numerical_variables=eda.get_numerical_variables()\n",
        "        \n",
        "    def dimentionality_reduction(self):\n",
        "        \n",
        "    def aggregate(self):\n",
        "        #normalize all the columns(features) so that all the values in the column lie between 0 and 1\n",
        "        #this way each features will get equal preference regardless of their actual range\n",
        "        n_data=pd.DataFrame(data=self.dataframe)\n",
        "        n_data[numerical_variables] = preprocessing.normalize(data),columns=numerical_variables\n",
        "        return n_data\n",
        "    \n",
        "    def transform(self):\n",
        "        #normalize all the columns(features) so that all the values in the column lie between 0 and 1\n",
        "        #this way each features will get equal preference regardless of their actual range\n",
        "        n_data=pd.DataFrame(data=self.dataframe)\n",
        "        n_data[numerical_variables] = preprocessing.normalize(data),columns=numerical_variables\n",
        "        return n_data"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}